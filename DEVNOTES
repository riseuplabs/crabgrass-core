crabgrass-core is a basic, paired down crabgrass.

things to work on
============================

directory
. group
. person

profiles
. me profile
. group profile
. profile in directory

account
. reset lost password
. cracklib

sphinx
. new sphinx
. better fields for sphinx
. get rid of page_terms

pages
. history
. attachments
. tags
. group search
. text page
. poll page
. asset page
. folder page

plugins
. write new plugin system

themes
. add more themes

tests
. minitest
. write more tests

i18n
. identify used and unused keys
. a system to translate
. better en.yml organization

misc
. replace backgroundrb

new features
. issues
. notices

internet explorer
============================

http://code.google.com/p/ie7-js/
make ie behave like a modern browser.

page changes
============================

assets for pages are not modular and should be defined in extensions/pages, instead of public/images.

schema changes
============================

todo:
  remove pages.message_count
  add pages.edits_count
  add page_terms.updated_by_ids
  add page_terms.watched_by_ids
  add page_terms.owner_id

it is really random what columns are indexed by page_terms and pages:

 pages:
   type, flow, created_at, updated_at, owner_name, name.

 page_terms:
   title, created_by_login, updated_by_login, owner_name, page_created_at,
   page_updated_at, created_by_id, updated_by_id, views_count, stars_count.

this should be cleaned up. i think a lot of these are unused, yet others may be needed. why do we have
created_by_login as a sortable index, but not contributors_count? do we really use the owner_name
indexes?

mailing list integration
=============================

two main problems: 

  (1) queuing and processing incoming messages
  (2) queuing outgoing messages

for incoming:

  Mailman (no, not that mailman, a ruby mailman)
  http://github.com/titanous/mailman
  http://rubydoc.info/github/titanous/mailman/master/file/USER_GUIDE.md
  point it at a maildir, and build easy routes based on conditions in the messages.

for outgoing:

  ARMailer: http://seattlerb.rubyforge.org/ar_mailer/
  ActionMailer::Queue: http://github.com/beam/action-mailer-queue/

  I think both do two phase delivery: when you send, it queues to db, then a bg process
  reads the queue and delivers the messages.

for background processing:

  starling for bg email processing: http://railscasts.com/episodes/128-starling-and-workling
  bj: http://codeforpeople.rubyforge.org/svn/bj/trunk/README

address formats:

  cgdev@we.riseup.net
  - new subject: create new discussion page in cgdev
  - old subject: append comment to existing page in cgdev

  cgdev+ui@we.riseup.net (for committees)

  cgdev+ui+70984@we.riseup.net
  - encode the page id in the return address. this way, we won't have problems parsing the subject. will this conflict with committee names? can committee names be just numbers?

requests
============================================

the queries that we seem to do the most for requests are slow with how the schema for requests works.

in particular, i think we might be doing a lot of queries for all the requests that relate to a given person or group, either as a creator or a recipient. the problem is that this requires a slow OR conditions, or a UNION.

it would make more sense to give requests just a column for user and a column for people, then use some other method to determine who the creator and recipient are...


jabber integration
==========================

openfire has a REST integration module:
https://we.riseup.net/cgdev/openfire-integration


calendars
======================================

https://github.com/vinsol/fullcalendar_rails
https://github.com/elevation/event_calendar

http://tenderapp.com/tour/ (not sure what this is)

documentation
=================================

http://yardoc.org/


delayed database updates
================================

Most of the database updates that are slow for the user are things that don't
need to be done right away. For example, you change one tiny thing about a page
and it kicks of tons and tons of database updates, but these are just for searching 
and could be delayed.

A huge speed improvement can be acheived by running these, and the sphinx indexing,
in background tasks.

background tasks
=====================

There is an incredible number of background processing options in rails.

lists:

* http://www.tobinharris.com/past/2009/3/9/6-ways-to-run-background-jobs-in-rubyonrails/
* http://oldwiki.rubyonrails.org/rails/pages/HowToRunBackgroundJobsInRails

This one looks good: https://github.com/stympy/delayed_job
It is a fork of delayed_job but with autoscaling.

Other links:

http://code.google.com/p/activemessaging/wiki/ActiveMessaging  
http://codeforpeople.rubyforge.org/svn/bj/trunk/README
https://github.com/barttenbrinke/worker_queue/
https://github.com/starling/active_queue

message/work processing queues:
  http://ap4r.rubyforge.org/wiki/wiki.pl?HomePage
  https://github.com/starling/starling
  http://kr.github.com/beanstalkd/

backgrounding code snippets:
  spawn
  http://code.google.com/p/asynchronous/
  https://github.com/imedo/background_lite

On linux, fixes thread timeout problems:
  http://systemtimer.rubyforge.org/
